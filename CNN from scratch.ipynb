{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import asarray\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv_layer:\n",
    "    def __init__(self,num_filters,filter_size):\n",
    "        self.num_filters = num_filters\n",
    "        self.filter_size = filter_size\n",
    "        self.conv_filter = np.random.randn(num_filters, filter_size, filter_size)/(filter_size*filter_size)\n",
    "        \n",
    "    def image_region(self,image):\n",
    "        height,width = image.shape\n",
    "        self.image = image\n",
    "        for j in range(height - self.filter_size + 1):\n",
    "            for k in range(width - self.filter_size + 1):\n",
    "                image_patch = image[ j : (j + self.filter_size), k : (k + self.filter_size)]\n",
    "                yield image_patch, j, k\n",
    "                \n",
    "            \n",
    "    def forward_prop(self,image):\n",
    "        height,width = image.shape\n",
    "        conv_out = np.zeros((height - self.filter_size + 1, width - self.filter_size + 1, self.num_filters ))\n",
    "        for image_patch, i, j in self.image_region(image):\n",
    "            conv_out[i, j] = np.sum(image_patch*self.conv_filter, axis = (1,2))\n",
    "        return conv_out\n",
    "        \n",
    "    def back_prop(self, dl_dout, learning_rate):\n",
    "        dl_df_params = np.zeros(self.conv_filter.shape)\n",
    "        for image_patch, i, j in self.image_region(self.image):\n",
    "            for k in range(self.num_filters):\n",
    "                dl_df_params[k] += image_patch*dl_dout[i, j, k]\n",
    "                    \n",
    "        \n",
    "        self.conv_filter -= learning_rate*dl_df_params\n",
    "        return dl_df_params\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Max_Pool:\n",
    "    def __init__(self,filter_size):\n",
    "        self.filter_size = filter_size\n",
    "        \n",
    "    def image_region(self,image):\n",
    "        self.image = image\n",
    "        new_height = image.shape[0]//self.filter_size\n",
    "        new_width = image.shape[1]//self.filter_size\n",
    "        \n",
    "        \n",
    "        for i in range(new_height):\n",
    "            for j in range(new_width):\n",
    "                image_patch = image[(i*self.filter_size) : (i*self.filter_size + self.filter_size), (j*self.filter_size) : (j*self.filter_size + self.filter_size)]\n",
    "                yield image_patch, i, j\n",
    "        \n",
    "    def forward_prop(self,image):\n",
    "        self.image = image\n",
    "        height, width, num_filters = image.shape\n",
    "        output = np.zeros((height//self.filter_size, width//self.filter_size ,num_filters))\n",
    "     \n",
    "        for image_patch, i, j in self.image_region(image):\n",
    "            output[i,j] = np.amax(image_patch, axis = (0,1))\n",
    "            \n",
    "        return output\n",
    "        \n",
    "        \n",
    "    def back_prop(self, dl_dout):\n",
    "        dl_dmax_pool = np.zeros(self.image.shape)\n",
    "        for image_patch, i, j in self.image_region(self.image):\n",
    "            height, width, num_filters = image_patch.shape\n",
    "            maximum_value = np.amax(image_patch, axis  = (0,1))\n",
    "                \n",
    "            for i1 in range(height):\n",
    "                for j1 in range(width):\n",
    "                    for k1 in range(num_filters):\n",
    "                        if image_patch[i1, j1, k1] == maximum_value[k1]:\n",
    "                            dl_dmax_pool[i*self.filter_size + i1, j*self.filter_size + j1, k1]=dl_dout[i,j,k1]\n",
    "                                                    \n",
    "        return dl_dmax_pool\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Softmax:\n",
    "    def __init__(self, input_node, softmax_node):\n",
    "        self.weight = np.random.randn(input_node, softmax_node)/input_node\n",
    "        self.bias = np.zeros(softmax_node)\n",
    "    \n",
    "    def forward_prop(self, image):\n",
    "        self.orig_im_shape = image.shape\n",
    "        image_modified = image.flatten()\n",
    "        self.modified_input = image_modified\n",
    "        output_val = np.dot(image_modified, self.weight) + self.bias\n",
    "        self.out = output_val\n",
    "        exp_out = np.exp(output_val)\n",
    "        return exp_out/np.sum(exp_out,axis = 0)\n",
    "    \n",
    "    def back_prop(self,dl_dout, learning_rate):\n",
    "        for i, grad in enumerate(dl_dout):\n",
    "            if grad == 0:\n",
    "                continue\n",
    "                \n",
    "            transformation_eq = np.exp(self.out)\n",
    "            s_total = np.sum(transformation_eq)\n",
    "        \n",
    "            dy_dz = -transformation_eq[i]*transformation_eq/(s_total**2)\n",
    "            dy_dz[i] = transformation_eq[i]*(s_total-transformation_eq[i])/(s_total**2)\n",
    "            \n",
    "            dz_dw = self.modified_input\n",
    "            dz_db = 1\n",
    "            dz_d_inp = self.weight\n",
    "            \n",
    "            dl_dz = grad * dy_dz\n",
    "            \n",
    "            dl_dw = dz_dw[np.newaxis].T @ dl_dz[np.newaxis]\n",
    "            dl_db = dl_dz * dz_db\n",
    "            dl_d_inp = dz_d_inp @ dl_dz\n",
    "            \n",
    "            self.weight -= learning_rate * dl_dw\n",
    "            self.bias -= learning_rate * dl_db\n",
    "        \n",
    "            return dl_d_inp.reshape(self.orig_im_shape)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 stpes out of 100 steps: Average loss 0.000 and Accuracy: 0%\n",
      "101 stpes out of 100 steps: Average loss 2.270 and Accuracy: 17%\n",
      "201 stpes out of 100 steps: Average loss 2.075 and Accuracy: 32%\n",
      "301 stpes out of 100 steps: Average loss 1.633 and Accuracy: 54%\n",
      "401 stpes out of 100 steps: Average loss 1.236 and Accuracy: 58%\n",
      "501 stpes out of 100 steps: Average loss 1.001 and Accuracy: 64%\n",
      "601 stpes out of 100 steps: Average loss 0.871 and Accuracy: 74%\n",
      "701 stpes out of 100 steps: Average loss 0.847 and Accuracy: 76%\n",
      "801 stpes out of 100 steps: Average loss 0.775 and Accuracy: 75%\n",
      "901 stpes out of 100 steps: Average loss 0.754 and Accuracy: 77%\n",
      "1001 stpes out of 100 steps: Average loss 0.489 and Accuracy: 88%\n",
      "1101 stpes out of 100 steps: Average loss 0.691 and Accuracy: 77%\n",
      "1201 stpes out of 100 steps: Average loss 0.647 and Accuracy: 79%\n",
      "1301 stpes out of 100 steps: Average loss 0.726 and Accuracy: 79%\n",
      "1401 stpes out of 100 steps: Average loss 0.605 and Accuracy: 77%\n",
      "1 stpes out of 100 steps: Average loss 0.000 and Accuracy: 0%\n",
      "101 stpes out of 100 steps: Average loss 0.641 and Accuracy: 81%\n",
      "201 stpes out of 100 steps: Average loss 0.639 and Accuracy: 75%\n",
      "301 stpes out of 100 steps: Average loss 0.496 and Accuracy: 86%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-85-969ebca9bad7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0mnum_correct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m         \u001b[0mli\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining_cnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0mli\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0mnum_correct\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-85-969ebca9bad7>\u001b[0m in \u001b[0;36mtraining_cnn\u001b[0;34m(image, label, learn_rate)\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mgrad_back\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msoftmax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mback_prop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearn_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mgrad_back\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mback_prop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad_back\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0mgrad_back\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mback_prop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad_back\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearn_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-53-62315af40988>\u001b[0m in \u001b[0;36mback_prop\u001b[0;34m(self, dl_dout, learning_rate)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mimage_patch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_region\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_filters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                 \u001b[0mdl_df_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mimage_patch\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mdl_dout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "(X_train,y_train),(X_test,y_test) = mnist.load_data()\n",
    "\n",
    "train_images = X_train[:1500]\n",
    "train_labels = y_train[:1500]\n",
    "\n",
    "test_images = X_test[:1500]\n",
    "test_labels = y_test[:1500]\n",
    "\n",
    "conv = Conv_layer(8,3)\n",
    "pool = Max_Pool(2)\n",
    "softmax = Softmax(13*13*8,10)\n",
    "\n",
    "def cnn_forward_prop(image, labels):\n",
    "    out_p = conv.forward_prop((image/255) - 0.5)\n",
    "    out_p = pool.forward_prop(out_p)\n",
    "    out_p = softmax.forward_prop(out_p)\n",
    "    \n",
    "    cross_entropy = -np.log(out_p[label])\n",
    "    accuracy_level = 1 if np.argmax(out_p ) == label else 0\n",
    "    \n",
    "    return out_p, cross_entropy, accuracy_level\n",
    "\n",
    "def training_cnn(image, label, learn_rate=.005):\n",
    "    out, loss, acc = cnn_forward_prop(image, label)\n",
    "    \n",
    "    gradient = np.zeros(10)\n",
    "    gradient[label] = -1/out[label]\n",
    "    \n",
    "    grad_back = softmax.back_prop(gradient, learn_rate)\n",
    "    grad_back = pool.back_prop(grad_back)\n",
    "    grad_back = conv.back_prop(grad_back, learn_rate)\n",
    "    \n",
    "    return loss, acc\n",
    "\n",
    "for epoch in range(10):\n",
    "    shuffle_data = np.random.permutation(len(train_images))\n",
    "    train_images = train_images[shuffle_data]\n",
    "    train_labels = train_labels[shuffle_data]\n",
    "    \n",
    "    loss = 0\n",
    "    num_correct = 0\n",
    "    for i, (im,label) in enumerate(zip(train_images, train_labels)):\n",
    "        if(i%100 == 0):\n",
    "            print(\"%d stpes out of 100 steps: Average loss %.3f and Accuracy: %d%%\" %(i+1,loss/100,num_correct))\n",
    "            loss = 0\n",
    "            num_correct = 0\n",
    "            \n",
    "        li,accuracy = training_cnn(im,label)\n",
    "        loss+=li\n",
    "        num_correct += accuracy\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
